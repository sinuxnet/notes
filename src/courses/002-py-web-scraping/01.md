# Web Scraping

3 tools to learn:

1. requests
2. Beautiful Soup
3. Scrapy

## Sending http requests

First step of web scraping is sending http requests. We use `requests` package in order to do our first step.

Getting start with `requests`:

```python
import requests

# GET
res = requests.get('https://x.com/home')

# POST
res = requests.post('https://x.com/posts',
                   data = {'key': 'value'})
# PUT
res = requests.put('https://x.com/posts/31',
                   data = {'key': 'value'})
# DELETE
res = requests.delete('https://x.com/posts/31')

# HEAD
res = requests.head('https://x.com/posts')

# OPTIONS
res = requests.options('https://x.com/posts/31')
```

 ```python
 import requests
 
 
 url = 'https://www.wikipedia.org/'
 response = requests.get(url)
 data = ""
 
 if response.status_code == 200:
     data = response.text
 else:
     data = f"Error: {response.status_code} - {response.reason}"
 
 print(data)
 
 ```

## Beautiful Soup

How to install?

```shell
$ pip install beautifulsoup4
```

```python
import requests
from bs4 import BeautifulSoup

url = "https://en.wikipedia.org/wiki/Mao_Zedong"
response = requests.get("https://en.wikipedia.org/wiki/Mao_Zedong")

content = BeautifulSoup(response.text)

print(content)
```

:warning: The code successfully will execute but we have this warning:

> GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("html.parser"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.
>
> The code that caused this warning is on line 6 of the file C:\python\web-scraping\03.py. To get rid of this warning, pass the additional argument 'features="html.parser"' to the BeautifulSoup constructor.

We usually use default `html.parser` but there are another parsers like:

* lxml
* lxml-xml
* html5lib

So to get rid of parser error we define beautifulsoup object like this:

```python
content = BeautifulSoup(response.text, "html.parser")
```

### bs4 methods

#### find()

It finds just first appearance of input value in content.

```python
print(content.find('h1'))
# <h1 class="firstHeading mw-first-heading" id="firstHeading"><span class="mw-page-title-main">Mao Zedong</span></h1>

print(content.find('h2'))
# <h2 class="vector-pinnable-header-label">Contents</h2>

```

#### find_all()

It finds all appearance of input value in content. It returns a list of values.

```python
print(content.find_all('h1'))
# [<h1 class="firstHeading mw-first-heading" id="firstHeading"><span class="mw-page-title-main">Mao Zedong</span></h1>]

print(content.find_all('h2'))
# [<h2 class="vector-pinnable-header-label">Contents</h2>, <h2 id="English_romanisation_of_name">English romanisation of name</h2>, <h2 id="Early_life">Early life</h2>, <h2 id="Early_revolutionary_activity">Early revolutionary activity</h2>]

print(content.find_all(['h1', 'h2']))
# [<h1 class="firstHeading mw-first-heading" id="firstHeading"><span class="mw-page-title-main">Mao Zedong</span></h1>, <h2 class="vector-pinnable-header-label">Contents</h2>, <h2 id="English_romanisation_of_name">English romanisation of name</h2>, <h2 id="Early_life">Early life</h2>, <h2 id="Early_revolutionary_activity">Early revolutionary activity</h2>]
```

How to get just attributes or just value of elements?

```python
print(content.find('h1').attrs)
# {'id': 'firstHeading', 'class': ['firstHeading', 'mw-first-heading']}

print(content.find('h1').text)
# Mao Zedong
```

How to find based on attributes?

```python
print(content.find(attrs={'role': 'note'}))
# <div class="hatnote navigation-not-searchable" role="note">For the TV series, see <a href="/wiki/Mao_Zedong_(TV_series)" title="Mao Zedong (TV series)"><i>Mao Zedong</i> (TV series)</a>.</div>

```

> [!NOTE]
>
> BS4's recommendation to find `class` attribute is use `class_` instead of `class` itself to avoid probable syntax error.

```python
print(content.find(class_='something'))
```

```python
print(content.find('h1', class_='something'))
```

```python
print(content.find('h1').get('id'))
# firstHeading
```

Use find with regex:

```python
import re

print(content.find(re.compile('^d')))
```

#### select()

It runs CSS selector against a parsed document and return all matching elements.

```python
print(content.select('li > a[title="Benjamin Tucker"]'))
# [<a href="/wiki/Benjamin_Tucker" title="Benjamin Tucker">Tucker</a>]
```

### Doing a Real World Example

  ```python
  import requests
  from bs4 import BeautifulSoup
  
  
  url = 'https://en.wikipedia.org/wiki/List_of_Game_of_Thrones_episodes'
  response = requests.get(url)
  
  content = BeautifulSoup(response.text, 'html.parser')
  
  episodes = []
  ep_tables = content.select("table.wikiepisodetable")
  
  
  for table in ep_tables:
      headers = []
      rows = table.find_all('tr')
      
      for header in table.find('tr').find_all('th'):
          headers.append(header.text)
      
      for row in table.find_all('tr')[1:]:
          values = []
          for col in row.find_all(['th', 'td']):
              values.append(col.text)
  
          if values:
              # episodes_dict = {headers[i]: values[i] for i in range(len(values))}
              episodes_dict = {}           
              for i in range(len(values)):
                  episodes_dict[headers[i]] = values[i]
                  
              episodes.append(episodes_dict)
  
  for episode in episodes:
      print(episode)
      
  ```
